#!/usr/bin/ipython
; -*- mode: python -*- #uncomment this when ready to run on server
#This script will take a list of SRA filenames (w/o .sra extension) and output a VCF file for each.
#for each sample, a tab-delimited .txt file is required containing:
#SRAReadGroupID	 SampleGroupID	 LibraryID       SeqPlatform	 paired/single
#ERR071082       ERS088906       ERX048850       illumina        paired
#Must be run from folder with indexed reference genome files in it as well as downloaded .sra files
#Must also have a folder within this folder called "trimfastqc"
#When running the script, type:
#ipython [path to script file] [path to .txt file] [.fasta reference file] [path to directory named "trim"]


import sys
import os
from datetime import datetime

InFileName = sys.argv[1]
Reference = sys.argv[2]
PathtoFastQ = sys.argv[3]

current_datetime = datetime.today().strftime("%d-%m-%Y-%H%M")

log_file = open('logfile_' + current_datetime , 'w')

log_file.write(current_datetime)
log_file.write(sys.argv[0] + ' ' + sys.argv[1] + ' ' + sys.argv[2] + ' ' + sys.argv[3])

def output_to_file(command):
	global log_file
	for string in get_ipython().getoutput(command):
		log_file.append(string)


def fastq_dump():
    output_to_file('/opt/PepPrograms/RGAPipeline/fastq-dump --split-files {RGID}.sra')

def fastqc():
    filename = RGID+ '_1.fastq'
    file = open(filename,'r')
    lines = file.readlines()
    fLine = lines[0]
    lposition = fLine.find('length')
    if lposition != -1:
        snum = fLine[lposition+7:len(fLine)-1]
    elif lposition == -1:
        snum = len(lines[1]) 
    numBP = int(snum)
    if pair == 'paired':
        output_to_file('/opt/PepPrograms/RGAPipeline/fastqc {RGID}_1.fastq {RGID}_2.fastq -t 6 -o ./fastqc')
    elif pair == 'single':
        output_to_file('/opt/PepPrograms/RGAPipeline/fastqc {RGID}_1.fastq')
    return numBP

def trim_galore():
    if pair == 'paired':
        output_to_file('/opt/PepPrograms/RGAPipeline/trim_galore -q 15 --fastqc_args "-t 6 -o ./trimfastqc"  -stringency 7 -o ./trim --paired --retain_unpaired {RGID}_1.fastq {RGID}_2.fastq')
    elif pair == 'single':
        output_to_file('/opt/PepPrograms/RGAPipeline/trim_galore -q 15 --fastqc_args "-t 6 -o ./trimfastqc"  -stringency 7 -o ./trim  {RGID}_1.fastq')
      

#Command to map with BWA (>70 bp)
def bwaMEM():
	global log_file
    log_file.write("inside mem")
    if pair =='paired':
	log_file.write("inside paired if")
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa mem -M -t 6 {Reference} {PathtoFastQ}/{RGID}_1_val_1.fq {PathtoFastQ}/{RGID}_2_val_2.fq > {RGID}.sam')
    elif pair == 'single':
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa mem -M -t 6 {Reference} {PathtoFastQ}/{RGID}_1_trimmed.fq > {RGID}.sam')

#Command to map with BWA (<70 bp)
def bwa():
    if pair == 'paired':
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa aln -t 6 {Reference} {PathtoFastQ}/{RGID}_1_val_1.fq > {RGID}_1.sai')
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa aln -t 6 {Reference} {PathtoFastQ}/{RGID}_2_val_2.fq > {RGID}_2.sai')
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa sampe -P {Reference} {RGID}_1.sai {RGID}_2.sai {PathtoFastQ}/{RGID}_1_val_1.fq {PathtoFastQ}/{RGID}_2_val_2.fq > {RGID}.sam')
    elif pair == 'single':
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa aln -t 6 {Reference} {PathtoFastQ}/{RGID}_1_trimmed.fq > {RGID}.sai')
        output_to_file('/opt/PepPrograms/RGAPipeline/bwa samse {Reference} {RGID}.sai {PathtoFastQ}/{RGID}_1_trimmed.fq > {RGID}.sam')

#Sort with samtools
def sort():
    output_to_file('/opt/PepPrograms/RGAPipeline/samtools view -bhSu {RGID}.sam | samtools sort - {RGID}.sort')

#Command to mark duplicates in your bam file
def dedup():
    output_to_file('java -Xmx2g -jar /opt/PepPrograms/RGAPipeline/MarkDuplicates.jar I={RGID}.sort.bam O={RGID}.dedup.bam M={RGID}.metrics REMOVE_DUPLICATES=true AS=true VALIDATION_STRINGENCY=SILENT')

#Command to add/replace read groups
def readgroups():
    output_to_file('java -Xmx2g -jar /opt/PepPrograms/RGAPipeline/AddOrReplaceReadGroups.jar I={RGID}.dedup.bam O={RGID}.ready.bam RGID={RGID} RGLB={RGLB} RGPL={RGPL} RGPU=dummy-barcode RGSM={RGSM} VALIDATION_STRINGENCY=SILENT SORT_ORDER=coordinate CREATE_INDEX=true')

#Command to Realign with GATK
def realign():
    output_to_file('java -jar /opt/PepPrograms/RGAPipeline/GenomeAnalysisTK.jar -I {RGID}.ready.bam -R {Reference} -T RealignerTargetCreator -o {RGID}.intervals')

    output_to_file('java -jar /opt/PepPrograms/RGAPipeline/GenomeAnalysisTK.jar -I {RGID}.ready.bam -R {Reference} -T IndelRealigner -targetIntervals {RGID}.intervals -o {RGID}.realn.bam')

#Command to Create VCF file
def vcf():
    output_to_file('java -jar /opt/PepPrograms/RGAPipeline/GenomeAnalysisTK.jar -I {RGID}.realn.bam -R {Reference} -T UnifiedGenotyper -o {RGID}.vcf -out_mode EMIT_ALL_CONFIDENT_SITES -stand_call_conf 20 -stand_emit_conf 20 --sample_ploidy 1 -nt 6 -rf BadCigar')
    output_to_file('java -jar /opt/PepPrograms/RGAPipeline/GenomeAnalysisTK.jar -I {RGID}.realn.bam -R {Reference} -T DepthOfCoverage -L {RGID}.intervals -U -S SILENT -rf BadCigar')

#Command to organize folder
def cleanup():
    output_to_file('mv {RGID}.vcf ./{projectname}_vcf')
    output_to_file('mv {RGID}.* ./intermediate_files')
    output_to_file('mv {RGID}_?.* ./intermediate_files')

InFile = open(InFileName, 'r')

projectname = InFileName.strip(".txt")

output_to_file('mkdir -p fastqc')
output_to_file('mkdir -p {projectname}_vcf')
output_to_file('mkdir -p trim')
output_to_file('mkdir -p intermediate_files')
filename = 'failed_'+InFileName
failedF = open(filename,'w')

filename2 = 'not_illumina_'+InFileName
failedplatform = open(filename2, 'w')

for line in InFile:
    numBP = 0
    line = line.strip()
    inputList = line.split()
    RGID = inputList[0]
    RGSM = inputList[1]
    RGLB = inputList[2]
    RGPL = inputList[3]
    pair = inputList[4]
    
    fastq_dump()
    log_file.write("fastq_dump completed")
    if RGPL != "illumina":
        failedplatform.write(line + '\n')
        failedF.write(RGID+ ' - not illumina' + '\n')
        continue
    if os.path.exists(RGID+'_2.fastq') != True and pair == 'paired':
        !rm {RGID}_1.fastq
        failedF.write(RGID + ' - fastq_dump' + '\n')
    else:
        log_file.write('2 files were created')
        numBP = fastqc()
        log_file.write("fastqc completed")
        trim_galore()
        log_file.write('trim_galore completed')
        if numBP >= 70:
            bwaMEM()
        else:
            bwa()
        if os.path.exists(RGID+'.sam') == True:
            log_file.write('bwa completed')
            sort()
            log_file.write('sort completed')
            dedup()
            log_file.write('dedup completed')
            readgroups()
            log_file.write('readgroups completed')
            realign()
            log_file.write('realign completed')
            vcf()
            log_file.write('vcf completed')
            if os.path.exists (RGID+'.vcf') == True:
               log_file.write('vcf completed')
               cleanup()
               log_file.write('cleanup completed')
            else:
               failedF.write(RGID + ' - vcf' + '\n')
        else:
            failedF.write(RGID + ' - bwa' + '\n')

#following code is for debugging purposes only:        
"""for line in InFile:
    line = line.strip()
    inputList = line.split()
    RGID = inputList[0]
    RGSM = inputList[1]
    RGLB = inputList[2]
    RGPL = inputList[3]
    pair = inputList[4]

    bwa()
    if os.path.exists(RGID+'.sam') == True:
        print('bwa completed')
        sort()
        print('sort completed')
        dedup()
        print('dedup completed')
        readgroups()
        print('readgroups completed')
        realign()
        print('realign completed')
        vcf()
        print('vcf completed')
        if os.path.exists (RGID+'.vcf') == True:
            print('vcf completed')
            cleanup()
            print ('cleanup completed')
        else:
            failedF.write(RGID + ' - vcf' + '\n')
    else:
        failedF.write(RGID + ' - bwa' + '\n')"""

InFile.close()
failedF.close()
failedplatform.close()
log_file.close()
